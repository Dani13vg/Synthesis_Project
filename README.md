# Instant -> Traducción

Welcome to our project! We are Neil de la Fuente, Nil Biescas, Xavier Soto, Jordi Longaron, and Daniel Vidal, and we have joined forces to revolutionize the way [iDisc, a translation company](https://www.idisc.com/en/), assigns tasks to its translators.

  
## Table of Contents

- [Project Overview](#Project-Overview)
- [Lab2](https://github.com/Neilus03/Spotiflyers/tree/main/Labs/Lab2)
- [Lab3](https://github.com/Neilus03/Spotiflyers/tree/main/Labs/Lab3)
- [Lab4](https://github.com/Neilus03/Spotiflyers/tree/main/Labs/Lab4)
- [Lab5](https://github.com/Neilus03/Spotiflyers/tree/main/Labs/Lab5)
- [Extra files](https://github.com/Neilus03/Spotiflyers/tree/main/Labs/Extra%20files)

## Project Overview

Our mission is to assist project managers at iDisc in making task assignments more efficient and effective. To achieve this, we have developed several machine learning models, including a Random Forest with Decision Trees and a Multilayer Perceptron (MLP). These models take into account various factors such as previous tasks completed by translators, client preferences, and features of the task at hand. The output is a list of top-k candidates best suited for a given task, making the assignment process streamlined and informed.

## Repository Structure


- `Decision_Trees/`: This directory contains Jupyter notebooks for the models we've built using decision trees. The notebooks included are "DecisionTrees_synthesis.ipynb" and "randomforest_synthesis.ipynb".
-
- `CheckPoints/`: This directory contains checkpoint files of the different models we've experimented with, each having its own unique configuration, such as batch sizes and the use of dropout techniques.
-
-
## Data

Here you have a link for the data needed for each of the model (Might be different data due to the difference between decision trees and neural networks):
- [Data for Decision Trees and Random Forest](https://drive.google.com/drive/folders/1rRwvEvHWddtyI-3mC2S8FqJHDPvdnrBc?usp=sharing)
- Data for MLP (Nil añadela)

Before the data is fed into our models, it undergoes a thorough preprocessing. This includes cleaning, normalization, and feature extraction, ensuring that our models receive quality data that helps them make the best predictions.

## How to Contribute

We welcome contributions! If you're interested in improving our models, fixing bugs, or adding new features, please feel free to make a pull request.

## Want to know more?

Soon the report on the project will be available for you to have a deeper understanding on our work. Stay tunned for updates!


## Contact

For any inquiries or issues, feel free to reach out to us.
