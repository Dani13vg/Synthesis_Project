{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ed5JGr6MIGTa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from Models.model import NeuralNet\n",
        "from Utils.utils_Dataset import process_dataset, OneHotDataframe\n",
        "\n",
        "from validation import validate\n",
        "from Utils.utils import TranslationDataset, make_loader\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In these notebook we will show some qualitative results about or Translators Model.\n",
        "We will follow this steps:\n",
        "1. Loading all the necessary data and functions\n",
        "2. Importing the models weights\n",
        "3. Making predictions with the model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPwJEyp1IG4V",
        "outputId": "cff0a945-4443-4342-e5e0-7e4e1aa2206b"
      },
      "outputs": [],
      "source": [
        "#pkl_file = '/home/xnmaster/Language_GrauIAI_UAB.pkl' #Pickle file path\n",
        "pkl_file = r\"C:\\Users\\34644\\Desktop\\Second Semester\\Synthesis Project\\Language_GrauIAI_UAB.pkl\"\n",
        "\n",
        "# Obtain the dataset\n",
        "Task_Data          = pd.read_pickle(pkl_file)               # Read the pkl file containg the pandas dataframe object\n",
        "Dataset_process    = process_dataset(Task_Data)             # Obtain the preprocess Dataset\n",
        "One_hot_Dataframe  = OneHotDataframe(Dataset_process)       # Changed categorical columns using one hot vectors\n",
        "num_classes = len(One_hot_Dataframe[\"TRANSLATOR\"].unique()) # Number of translators\n",
        "input_size  = len(One_hot_Dataframe.columns) - 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = NeuralNet(input_size, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9qwljCY9IG7K"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = torch.load(r'C:\\Users\\34644\\Desktop\\Second Semester\\Synthesis Project\\Code_Project\\CheckPoints\\256_Batch_Size_30_epocs.pth', map_location=\"cpu\")\n",
        "model.load_state_dict(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "X                  = One_hot_Dataframe.loc[:, One_hot_Dataframe.columns != 'TRANSLATOR'] # Features\n",
        "Translators        = One_hot_Dataframe['TRANSLATOR']   \n",
        "\n",
        "Splits_Train_Test  = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
        "Train_Test_indices = Splits_Train_Test.split(X, Translators)\n",
        "\n",
        "train_indices, test_indices = next(Train_Test_indices)\n",
        "\n",
        "Dataset = TranslationDataset(One_hot_Dataframe, X.values, test_indices)\n",
        "DataLoader = make_loader(Dataset, 64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN7c6dsWJKxq",
        "outputId": "234b7490-98f3-45a0-f1ca-fec78c37d966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0059, Accuracy: 56283/63485 (89%)\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.005912481310931474, 88.65558793415768)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Validation of the model. Needed of gpu to check it.\n",
        "# criterion = torch.nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
        "# validate(criterion, model, DataLoader, device = 'cuda')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRPU-xcpKuti"
      },
      "outputs": [],
      "source": [
        "def obtain_input_vector(X, \n",
        "                        PM,\n",
        "                        TASK_TYPE, \n",
        "                        SOURCE_LANG, \n",
        "                        TARGET_LANG, \n",
        "                        FORECAST, \n",
        "                        HOURLY_RATE,\n",
        "                        COST, \n",
        "                        QUALITY_EVALUATION, \n",
        "                        MANUFACTURER, \n",
        "                        MANUFACTURER_SECTOR):\n",
        "    \n",
        "    new_row = pd.Series(np.zeros(len(X.columns)), index=X.columns)\n",
        "\n",
        "    new_row['FORECAST'], new_row['HOURLY_RATE'], new_row['QUALITY_EVALUATION'], new_row['COST'] = FORECAST, HOURLY_RATE, QUALITY_EVALUATION, COST\n",
        "\n",
        "    new_row['PM_' + PM]                                 = 1           \n",
        "    new_row['TASK_TYPE_' + TASK_TYPE]                   = 1\n",
        "    new_row['SOURCE_LANG_' + SOURCE_LANG]               = 1\n",
        "    new_row['TARGET_LANG_' + TARGET_LANG]               = 1\n",
        "    new_row['MANUFACTURER_'+ MANUFACTURER]              = 1\n",
        "    new_row['MANUFACTURER_SECTOR_'+MANUFACTURER_SECTOR] = 1\n",
        "\n",
        "    return torch.tensor(new_row.values, dtype=torch.float32) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXp5M1qXKV8U"
      },
      "outputs": [],
      "source": [
        "new_row = obtain_input_vector(One_hot_Dataframe.loc[:, One_hot_Dataframe.columns != 'TRANSLATOR'],\n",
        "                    PM = \"PMT\",\n",
        "                    TASK_TYPE = \"ProofReading\", \n",
        "                    SOURCE_LANG = \"English\", \n",
        "                    TARGET_LANG = \"Spanish (Iberian)\", \n",
        "                    FORECAST = 0.28,\n",
        "                    HOURLY_RATE = 23,\n",
        "                    COST = 6.44,\n",
        "                    QUALITY_EVALUATION = 6, \n",
        "                    MANUFACTURER = 'MotorForge', \n",
        "                    MANUFACTURER_SECTOR = 'Consumer Discretionary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vzYo2dOuN5yz",
        "outputId": "a7e50d8e-2007-43fc-b5a1-e53fd4992a21"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5bc9f2eb-eb49-4818-bb43-d3f9de67c461\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Translator</th>\n",
              "      <th>Suitability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Enith</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maximo</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Margarita</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fortunato</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Paula</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Abelardo</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Rafaela</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Luis Felipe</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Porfirio</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bc9f2eb-eb49-4818-bb43-d3f9de67c461')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5bc9f2eb-eb49-4818-bb43-d3f9de67c461 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5bc9f2eb-eb49-4818-bb43-d3f9de67c461');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Translator  Suitability\n",
              "0    Christian         0.54\n",
              "1        Enith         0.26\n",
              "2       Maximo         0.14\n",
              "3    Margarita         0.02\n",
              "4    Fortunato         0.01\n",
              "5        Paula         0.01\n",
              "6     Abelardo         0.01\n",
              "7      Rafaela         0.00\n",
              "8  Luis Felipe         0.00\n",
              "9     Porfirio         0.00"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def return_top_10(input, num):\n",
        "    Softmax = nn.Softmax(dim=1)\n",
        "    output = model(input)\n",
        "    output_softmax = Softmax(output.unsqueeze(0))\n",
        "    sorted_values, sorted_indices = torch.sort(output_softmax, descending=True)\n",
        "    sorted_values, sorted_indices = sorted_values[0][:num], sorted_indices[0][:num]\n",
        "    mapped_list_comprehension = [(Dataset.Labels2Translator[int(num)], round(float(values), 2)) for num, values in zip(sorted_indices, sorted_values)]\n",
        "\n",
        "    return pd.DataFrame(mapped_list_comprehension, columns=['Translator', 'Suitability'])\n",
        "\n",
        "return_top_10(new_row.to('cuda'), 10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LurIfmmZOA7T"
      },
      "outputs": [],
      "source": [
        "model = model.to('cuda')\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "model.eval()\n",
        "for data, label in DataLoader:\n",
        "    data, label = data.to('cuda'), label.to('cuda')\n",
        "\n",
        "    output = model(data)                                                         \n",
        "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    y_true.append(label.tolist())\n",
        "    y_pred.append(pred.squeeze().tolist())                                                       \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWekWdHoOHuA"
      },
      "outputs": [],
      "source": [
        "y_true = [[Dataset.Labels2Translator[int(translator_idx)] for translator_idx in list_true] for list_true in y_true]\n",
        "y_pred = [[Dataset.Labels2Translator[int(translator_idx)] for translator_idx in list_pred] for list_pred in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VblIhwJmOLGZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from itertools import chain\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "def bio_classification_report(y_true, y_pred):\n",
        "    \"\"\"\n",
        "\n",
        "    Classification report.\n",
        "    You can use this as evaluation for both in the baseline model and new model.\n",
        "    \"\"\"\n",
        "    lb = LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "        \n",
        "    tagset = set(lb.classes_) - {'O'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "    \n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsyTA26yOMR4",
        "outputId": "eb98966e-2196-4b25-a454-4fe2070da582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translators evaluation\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "           Abelardo       0.92      0.89      0.90       999\n",
            "      Acacio Poncio       0.98      0.98      0.98      1730\n",
            " Adalberto Anatolio       0.87      0.97      0.92      3078\n",
            "             Agueda       0.99      0.96      0.98      2860\n",
            "          Alejandro       0.81      0.87      0.84       982\n",
            "              Aline       1.00      0.99      1.00      1904\n",
            "    Almudena Fiamma       0.99      0.97      0.98      1717\n",
            "              Amaro       0.79      0.74      0.76      1273\n",
            "      Ambrosia Adon       0.64      0.98      0.77      3432\n",
            "        Ana Daniela       0.91      0.90      0.90       497\n",
            "    Anselma Daciano       0.74      0.84      0.79      1592\n",
            "    Ariadna Laurina       0.92      0.86      0.89      2829\n",
            "    Artur Fulgencio       0.00      0.00      0.00      2880\n",
            "          Ascension       0.96      0.99      0.98      7438\n",
            "            Beatriz       0.99      0.71      0.82       605\n",
            "             Breixo       1.00      0.98      0.99      1904\n",
            "             Carles       0.45      0.03      0.06      1096\n",
            "            Casiano       0.75      0.98      0.85      9067\n",
            "              Celso       0.98      0.88      0.92      2565\n",
            "             Celton       0.96      0.97      0.97       808\n",
            "          Christian       0.67      0.57      0.62       612\n",
            "  Columbano Cleofas       0.95      0.87      0.91      3136\n",
            "    Conchi Marciano       0.91      0.46      0.62       637\n",
            " Constantino Carmen       0.86      0.83      0.84      1277\n",
            "         Dacio Abel       0.98      0.99      0.99      5382\n",
            "     Daiana Rosario       0.95      0.98      0.97      7528\n",
            "            Damiana       1.00      1.00      1.00      1757\n",
            "              Dario       0.98      0.97      0.97      1498\n",
            "      David Antonio       0.96      0.98      0.97       949\n",
            "            Edmundo       0.98      0.98      0.98      1963\n",
            "       Elias Daiana       0.94      0.96      0.95      1120\n",
            "             Eliseo       0.98      0.99      0.98      2224\n",
            "              Enith       0.61      0.71      0.65       716\n",
            "              Erico       0.81      0.93      0.86      2034\n",
            "              Ester       0.71      0.22      0.34      1597\n",
            "          Fortunato       0.96      0.93      0.95      1172\n",
            "     Francisco Jose       0.80      0.62      0.70       564\n",
            "               Gala       0.99      1.00      0.99     12621\n",
            "              Gorka       0.98      0.97      0.98       876\n",
            "    Gregorio Monica       0.63      0.22      0.32       970\n",
            "      Greta Casiano       0.68      0.97      0.80      1213\n",
            "Guadalupe Ildefonso       0.83      0.58      0.68       609\n",
            "              Guido       0.79      0.72      0.76       483\n",
            "             Hector       1.00      1.00      1.00       611\n",
            " Ildefonso Ambrosio       0.97      0.95      0.96      1003\n",
            "    Inocencio Lucas       0.94      0.97      0.96      3871\n",
            "             Ireneo       0.79      0.89      0.84      2346\n",
            "    Isaias Venancio       0.97      0.96      0.97     14556\n",
            "              Ivana       0.84      0.90      0.87       840\n",
            "         Jonas Tito       0.96      0.98      0.97      1197\n",
            "       Jose Ignacio       0.41      0.04      0.08       742\n",
            "        Juan Carlos       0.82      0.95      0.88      1835\n",
            "    Juvenal Vicente       0.83      0.79      0.81      1649\n",
            "              Killa       0.97      1.00      0.98      1430\n",
            "   Laureano Facundo       0.92      0.90      0.91       844\n",
            "     Laurina Rafael       0.91      0.84      0.87      1398\n",
            "   Laurina Santiago       0.47      0.10      0.17       742\n",
            "             Lucano       0.83      0.69      0.75       660\n",
            "        Luis Felipe       0.96      0.95      0.96      3172\n",
            "     Marcelo German       0.78      0.73      0.75      1022\n",
            "             Marcos       0.97      0.98      0.98      2031\n",
            "          Margarita       0.77      0.59      0.67       589\n",
            "       Maria Aurora       0.58      0.72      0.64      1252\n",
            "     Maria Fernanda       0.80      0.83      0.81      1557\n",
            "      Mariano Fidel       0.66      0.95      0.78      2793\n",
            "  Mariano Valeriano       0.95      0.93      0.94       742\n",
            "             Markel       0.89      0.95      0.92      1333\n",
            "             Maximo       0.95      0.98      0.96       825\n",
            "  Mercedes Catalina       0.90      0.82      0.86       797\n",
            "    Nieves Leocadia       0.93      0.97      0.95      2915\n",
            "             Octavi       0.84      0.46      0.60       624\n",
            "       Octavio Jana       0.83      0.68      0.74      1750\n",
            "              Oscar       0.69      0.81      0.75      1124\n",
            "      Otilia Rebeca       0.80      0.93      0.86      1315\n",
            "       Pablo Martin       0.90      0.67      0.77       601\n",
            "   Pancracio Adolfo       0.80      0.72      0.76       987\n",
            "              Paula       0.81      0.94      0.87       890\n",
            "  Petronila Teofila       0.89      0.89      0.89      3332\n",
            "            Pio Pio       0.28      0.06      0.09       756\n",
            "           Porfirio       0.70      0.97      0.81       675\n",
            "           Priscila       0.93      0.84      0.88      2276\n",
            "            Rafaela       0.97      0.98      0.98      1064\n",
            "     Ramiro Josafat       0.84      0.89      0.87      2443\n",
            "      Roque Marlene       0.91      0.94      0.92      1632\n",
            "               Rufo       0.77      0.59      0.67       945\n",
            "    Salma Benedicto       0.62      0.66      0.64       579\n",
            "             Salome       0.67      0.91      0.77       765\n",
            "               Sara       0.98      0.93      0.96       501\n",
            "           Severino       0.95      0.72      0.82       932\n",
            "            Sussana       0.96      0.92      0.94      1500\n",
            "     Ubaldo Maitane       0.71      0.87      0.78       658\n",
            "   Victorino Yamila       0.98      0.94      0.96      1684\n",
            "           Vinicius       0.99      0.98      0.98      1927\n",
            "              Xoana       0.89      0.96      0.93      8549\n",
            "\n",
            "          micro avg       0.89      0.89      0.89    190455\n",
            "          macro avg       0.84      0.81      0.81    190455\n",
            "       weighted avg       0.87      0.89      0.87    190455\n",
            "        samples avg       0.89      0.89      0.89    190455\n",
            "\n"
          ]
        }
      ],
      "source": [
        "TRANSLATORS = bio_classification_report(y_true, y_pred)\n",
        "print('Translators evaluation')\n",
        "print(TRANSLATORS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l0KdkskOmJy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
